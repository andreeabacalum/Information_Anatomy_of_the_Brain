{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conducting Supervised Learning to predict context values per timepoint(only including timepoints where a word was spoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n",
    "import pickle\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concat_spoken_fmri():\n",
    "    '''\n",
    "    Concatenate fMRI data across subjects for timepoints where a word was spoken\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fmri_array : np.ndarray\n",
    "        2d array representing the concatenated fMRI data across all subjects where a word was spoken, with data concatenated along the x-axis\n",
    "    \"\"\"\n",
    "    '''\n",
    "    all_chopped_fmri = []\n",
    "    for i in range(1, 87):\n",
    "        chopped_fmri = pd.read_csv(f'/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/fMRI_sub_{i}_spoken_timepoints_new.csv', header=None)\n",
    "        all_chopped_fmri.append(chopped_fmri.values)\n",
    "        \n",
    "    ## First, we build the predictor by concatenating accross the x-axis all the fMRI data for each subject where a word was spoken\n",
    "    fmri_array = all_chopped_fmri[0]\n",
    "    for array in all_chopped_fmri[1:]:\n",
    "        fmri_array = np.concatenate((fmri_array, array), axis=1)\n",
    "    \n",
    "    np.savetxt('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/predictor_fMRI_concatenated_NEW.csv', fmri_array, delimiter =',')\n",
    "    return fmri_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73611298e-01,  8.86672363e-02, -9.72323269e-02, ...,\n",
       "        -1.02434628e-01,  4.59222049e-01,  6.86753392e-01],\n",
       "       [-7.08576068e-02,  2.51554281e-01, -3.14064295e-04, ...,\n",
       "        -5.15036941e-01, -2.86967337e-01, -3.15023661e-01],\n",
       "       [-3.96565832e-02, -4.63391840e-02, -4.78670001e-02, ...,\n",
       "        -3.45937431e-01, -8.14586878e-03,  3.92116845e-01],\n",
       "       ...,\n",
       "       [ 8.86890963e-02, -1.22874796e-01, -7.55924452e-03, ...,\n",
       "         1.68961108e-01,  2.19348922e-01,  1.23490781e-01],\n",
       "       [ 1.59149379e-01,  1.62857957e-02, -2.60403782e-01, ...,\n",
       "         3.02624494e-01,  5.47391117e-01,  4.53376979e-01],\n",
       "       [-6.71684325e-01, -4.80926901e-01, -2.71127611e-01, ...,\n",
       "         1.06237876e+00,  6.81948483e-01,  9.97906327e-01]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_spoken_fmri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'5470': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], '6804': [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], '7715': [81, 82, 83, 84, 85, 86], '6674': [63, 64, 65, 66, 67, 68], '5900': [75, 76, 77, 78, 79, 80], '7515': [57, 58, 59, 60, 61, 62], '8882': [45, 46, 47, 48, 49, 50], '8181': [51, 52, 53, 54, 55, 56], '6739': [69, 70, 71, 72, 73, 74], '6102': [39, 40, 41, 42, 43, 44]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_subjects_by_films(i):\n",
    "    '''\n",
    "    Conctructing the target variable -concatenating context value per timepoint per subject\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    i (int) : subject id\n",
    "    '''\n",
    "    #splitting subjects by the film they have watched\n",
    "    all_film_paths_dict = {'5470':[], '6804':[],'7715':[],'6674':[], '5900':[], '7515':[], '8882':[], '8181':[], '6739':[], '6102':[]}\n",
    "    for i in range(1,87):\n",
    "        split_subjects_by_films(i)\n",
    "    data=loadmat(f'/rds/general/user/ab5621/home/Masters-Dissertation/Helper Files/extended_schaefer_200/sub-{i}/full_ts.mat')\n",
    "    data = data['data']\n",
    "    data = np.mean(data, axis=0)\n",
    "\n",
    "    for film_length in all_film_paths_dict.keys():\n",
    "        if len(data) == int(film_length):\n",
    "            all_film_paths_dict[film_length].append(i)\n",
    "\n",
    "for i in range(1,87):\n",
    "    split_subjects_by_films(i)\n",
    "\n",
    "print(all_film_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_target_contextval():\n",
    "    '''\n",
    "    Concatenated context values to build target variable for the supervised learning algorithm\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    targets_list (list): a list of context values for each word in each film viewed by each subject\n",
    "    '''\n",
    "\n",
    "    #splitting subjects by the film they have watched\n",
    "    all_film_paths_dict = {'5470':[], '6804':[],'7715':[],'6674':[], '5900':[], '7515':[], '8882':[], '8181':[], '6739':[], '6102':[]}\n",
    "\n",
    "    for i in range(1,87):\n",
    "        split_subjects_by_films(i)\n",
    "    targets_list = []\n",
    "    for subject_id in range(1, 87):\n",
    "        for film_length in all_film_paths_dict.keys():\n",
    "            #Getting the right film for each subject\n",
    "            if film_length == '5470':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_500_days_of_summer_words_new.json.json.json'\n",
    "            if film_length == '6804':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_citizenfour_words_new.json.json.json'\n",
    "            if film_length == '7715':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_12_years_a_slave_words_new.json.json.json'\n",
    "            if film_length == '6674':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_back_to_the_future_words_new.json.json.json'\n",
    "            if film_length == '5900':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_little_miss_sunshine_words_new.json.json.json'\n",
    "            if film_length == '7515':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_the_prestige_words_new.json.json.json'\n",
    "            if film_length == '8882':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_pulp_fiction_words_new.json.json.json'\n",
    "            if film_length == '8181':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_the_shawshank_redemption_words_new.json.json.json'\n",
    "            if film_length == '6739':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_split_words_new.json.json.json'\n",
    "            if film_length == '6102':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/context_values/att_405overlap_per_timepoint_405_overlap_word_level_attention_the_usual_suspects_words_new.json.json.json'\n",
    "            if subject_id in all_film_paths_dict[film_length]:\n",
    "\n",
    "                with open(movie_context_path, 'r') as attention_file:\n",
    "                    att = json.load(attention_file)\n",
    "\n",
    "                for att_val in att.values():\n",
    "         \n",
    "                    targets_list.append(att_val)\n",
    "    np.savetxt('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/supervised_learning/concat_target.csv', targets_list, delimiter=',')\n",
    "    return targets_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surprisal_split.txt', 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    surprisals = file.read()\n",
    "tuple_strings = re.findall(r'\\(([^)]+)\\)', surprisals)\n",
    "\n",
    "\n",
    "def str_to_tuple(s):\n",
    "    '''\n",
    "    converts a string representation of a tuple to a tuple of integers\n",
    "    '''\n",
    "    return tuple(map(lambda x: float(x), s.split(',')))\n",
    "\n",
    "# Convert each tuple string to a tuple of integers\n",
    "tuples = [str_to_tuple(ts) for ts in tuple_strings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprisals_per_timepoint(surprisal_path):\n",
    "    '''\n",
    "    Build average surprisal values per timepoint\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    surprisal_path : str\n",
    "        local file path containing surprisal values and timepoints\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    target_surprisals_with_time : dict\n",
    "        dictionary where the keys are timepoints and the values are the average surprisal values for all words spoken during that timepoint\n",
    "    \n",
    "    '''\n",
    "    with open(surprisal_path, 'r') as file:\n",
    "        # Read the contents of the file\n",
    "        surprisals = file.read()\n",
    "    tuple_strings = re.findall(r'\\(([^)]+)\\)', surprisals)\n",
    "\n",
    "    #converting back to floats\n",
    "    new_surprisals = [str_to_tuple(ts) for ts in tuple_strings]\n",
    "    new_surprisals_for_film = [[surp, math.ceil(float(time))] for (surp, time) in new_surprisals]\n",
    "    target_surprisals_with_time = {time: [] for [key, time] in new_surprisals_for_film}\n",
    "\n",
    "    for word_surp in new_surprisals_for_film:\n",
    "        target_surprisals_with_time[word_surp[1]].append(word_surp[0])\n",
    "    #Averages for the surprisal of all words spoken in the TR-1 and Tr\n",
    "    target_surprisals_with_time = {key: sum(values) / len(values) for key, values in target_surprisals_with_time.items()}\n",
    "\n",
    "    \n",
    "    return target_surprisals_with_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_regions():\n",
    "    \"\"\"\n",
    "    Extract only brain regions involved in language processing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_fMRI_only_spoken_timepoints : np.ndarray\n",
    "        A np array containing fMRI data for language-related brain regions at the timepoints where a word was spoken\n",
    "    \"\"\"\n",
    "    #load the names of all regions\n",
    "    extended_schaefer_200_data = pd.read_csv('/rds/general/user/ab5621/home/Masters-Dissertation/Helper Files/extended_schaefer_200 (1).csv')\n",
    "\n",
    "    #list of the subset of regions that are involved in language\n",
    "    language_related_regions = [\"Aud 1\", \"Aud 2\", \"Aud 3\", \"FrOper 1\", \"FrOper 2\", \"TempPole 1\", \"TempPole 2\", \"TempPole 3\", \"TempPole 4\", \"Temp 1\", \"Temp 2\", \"Temp 3\", \"Temp 4\", \"IPL 1\", \"IPL 2\", \"TempPar 1\", \"TempPar 2\", \"TempPar 3\", \"TempPar 4\", \"IPS 1\", \"IPS 2\", \"ParOper 1\", \"ParMed 1\", \"ParMed 2\", \"PrC 1\", \"Cent 1\", \"Cent 2\"]\n",
    "\n",
    "    #filtering the dataframe to contain only language regions\n",
    "    filtered_df = extended_schaefer_200_data[extended_schaefer_200_data['region'].isin(language_related_regions)]\n",
    "    labels_list = filtered_df['label'].tolist()\n",
    "\n",
    "    #taking the indexes of language regions in the dataframe\n",
    "    language_indexes = [x - 1 for x in labels_list]\n",
    "    language_indexes_2 = [element+232 for element in language_indexes]\n",
    "    language_indexes_3 = [element+232 for element in language_indexes_2]\n",
    "\n",
    "    all_language_indexes = language_indexes + language_indexes_2+language_indexes_3\n",
    "\n",
    "    #taking only the brain regions which are involved in language as features\n",
    "    all_fMRI_only_spoken_timepoints = pd.read_csv('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/predictor_fMRI_concatenated_NEW.csv', header=None)\n",
    "    all_fMRI_only_spoken_timepoints = np.array(all_fMRI_only_spoken_timepoints)\n",
    "    all_fMRI_only_spoken_timepoints = all_fMRI_only_spoken_timepoints[language_indexes, :]\n",
    "    np.savetxt('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/predictor_fMRI_language_regions.csv', all_fMRI_only_spoken_timepoints, delimiter =',')\n",
    "\n",
    "    return all_fMRI_only_spoken_timepoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting surprisal target values\n",
    "\n",
    "def concat_target_surprisal():\n",
    "    \"\"\"\n",
    "    Concatenates surprisal values for all subjects\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    targets_list : list of float\n",
    "        list containing all concatenated surprisal values from the films watched by all subjects\n",
    "    \"\"\"\n",
    "    #splitting subjects by the film they have watched\n",
    "    all_film_paths_dict = {'5470':[], '6804':[],'7715':[],'6674':[], '5900':[], '7515':[], '8882':[], '8181':[], '6739':[], '6102':[]}\n",
    "    for i in range(1,87):\n",
    "        split_subjects_by_films(i)\n",
    "        \n",
    "    targets_list = []\n",
    "    for subject_id in range(1, 87):\n",
    "\n",
    "        for film_length in all_film_paths_dict.keys():\n",
    "            #Getting the right film for each subject\n",
    "            if film_length == '5470':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_500_days_of_summer.pkl'\n",
    "            if film_length == '6804':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_citizenfour.pkl'\n",
    "            if film_length == '7715':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_12_years_of_slave.pkl'\n",
    "            if film_length == '6674':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_back_to_the_future.pkl'\n",
    "            if film_length == '5900':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_little_miss_sunshine.pkl'\n",
    "            if film_length == '7515':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_the_prestige.pkl'\n",
    "            if film_length == '8882':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_pulp_fiction.pkl'\n",
    "            if film_length == '8181':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_the_shawshank_redemption.pkl'\n",
    "            if film_length == '6739':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_split.pkl'\n",
    "            if film_length == '6102':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_the_usual_suspects.pkl'\n",
    "            if subject_id in all_film_paths_dict[film_length]:\n",
    "\n",
    "                with open(movie_context_path, 'rb') as surprisal_file:\n",
    "                    att = pickle.load(surprisal_file)\n",
    "                #Loading context values\n",
    "                for att_val in att.values():\n",
    "                    targets_list.append(att_val)\n",
    "    np.savetxt('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/target_surprisals.csv', targets_list, delimiter=',')\n",
    "    return targets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GETTING times when a word was spoken\n",
    "\n",
    "def spoken_times():\n",
    "    '''\n",
    "    Extract synergy, redundancy, and unique information at the timepoints where a word was spoken, for all subjects\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    final_list : np.ndarray\n",
    "        2D array containing concatenated synergy, redundancy, and unique information for all subjects at the timepoints where a word was spoken\n",
    "\n",
    "    '''\n",
    "    #splitting subjects by the film they have watched\n",
    "    all_film_paths_dict = {'5470':[], '6804':[],'7715':[],'6674':[], '5900':[], '7515':[], '8882':[], '8181':[], '6739':[], '6102':[]}\n",
    "    for i in range(1,87):\n",
    "        split_subjects_by_films(i)\n",
    "    targets_list = []\n",
    "    for subject_id in range(1, 87):\n",
    "        syn_data = pd.read_csv(f'/rds/general/user/ab5621/home/Masters-Dissertation/Results/Dynamic_Information/{subject_id}_dynamic_synergy.csv', header=None)\n",
    "        red_data = pd.read_csv(f'/rds/general/user/ab5621/home/Masters-Dissertation/Results/Dynamic_Information/{subject_id}_dynamic_redundancy.csv', header=None)\n",
    "        uni_data = pd.read_csv(f'/rds/general/user/ab5621/home/Masters-Dissertation/Results/Dynamic_Information/{subject_id}_dynamic_unique.csv', header=None)\n",
    "        syn_data = np.array(syn_data)\n",
    "        red_data = np.array(red_data)\n",
    "        uni_data = np.array(uni_data)\n",
    "        for film_length in all_film_paths_dict.keys():\n",
    "            #Getting the right film for each subject\n",
    "            if film_length == '5470':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_500_days_of_summer.pkl'\n",
    "            if film_length == '6804':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_citizenfour.pkl'\n",
    "            if film_length == '7715':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_12_years_of_slave.pkl'\n",
    "            if film_length == '6674':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_back_to_the_future.pkl'\n",
    "            if film_length == '5900':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_little_miss_sunshine.pkl'\n",
    "            if film_length == '7515':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_the_prestige.pkl'\n",
    "            if film_length == '8882':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_pulp_fiction.pkl'\n",
    "            if film_length == '8181':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_the_shawshank_redemption.pkl'\n",
    "            if film_length == '6739':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_split.pkl'\n",
    "            if film_length == '6102':\n",
    "                movie_context_path = '/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/surp_per_timepoint_the_usual_suspects.pkl'\n",
    "            if subject_id in all_film_paths_dict[film_length]:\n",
    "\n",
    "                with open(movie_context_path, 'rb') as surprisal_file:\n",
    "                    surprisal = pickle.load(surprisal_file)\n",
    "\n",
    "                timings = list(surprisal.keys())\n",
    "                timings_list = [time-1 for time in timings]\n",
    "                print(syn_data.shape)\n",
    "                syn_data = syn_data[:, timings_list]\n",
    "                red_data = red_data[:, timings_list]\n",
    "                uni_data = uni_data[:, timings_list]\n",
    "                all_info_list = [syn_data, red_data, uni_data]\n",
    "                concat_all_info_one_subj = np.concatenate(all_info_list, axis=0)\n",
    "       \n",
    "    \n",
    "                targets_list.append(concat_all_info_one_subj)\n",
    "    final_list = np.concatenate(targets_list, axis=1)\n",
    "    np.savetxt('/rds/general/user/ab5621/home/Masters-Dissertation/movie_subtitles/surprisal/allinfo_only_spoken_timepoints.csv', final_list, delimiter=',')\n",
    "    return final_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
